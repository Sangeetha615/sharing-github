{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file\n",
      " Google's toolbar sparks concern\n",
      "\n",
      "Search engine firm Google has released a trial tool which is concerning some net users because it directs people to pre-selected commercial websites.\n",
      "\n",
      "The AutoLink feature comes with Google's latest toolbar and provides links in a webpage to Amazon.com if it finds a book's ISBN number on the site. It also links to Google's map service, if there is an address, or to car firm Carfax, if there is a licence plate. Google said the feature, available only in the US, \"adds useful links\". But some users are concerned that Google's dominant position in the search engine market place could mean it would be giving a competitive edge to firms like Amazon.\n",
      "\n",
      "AutoLink works by creating a link to a website based on information contained in a webpage - even if there is no link specified and whether or not the publisher of the page has given permission.\n",
      "\n",
      "If a user clicks the AutoLink feature in the Google toolbar then a webpage with a book's unique ISBN number would link directly to Amazon's website. It could mean online libraries that list ISBN book numbers find they are directing users to Amazon.com whether they like it or not. Websites which have paid for advertising on their pages may also be directing people to rival services. Dan Gillmor, founder of Grassroots Media, which supports citizen-based media, said the tool was a \"bad idea, and an unfortunate move by a company that is looking to continue its hypergrowth\". In a statement Google said the feature was still only in beta, ie trial, stage and that the company welcomed feedback from users. It said: \"The user can choose never to click on the AutoLink button, and web pages she views will never be modified. \"In addition, the user can choose to disable the AutoLink feature entirely at any time.\"\n",
      "\n",
      "The new tool has been compared to the Smart Tags feature from Microsoft by some users. It was widely criticised by net users and later dropped by Microsoft after concerns over trademark use were raised. Smart Tags allowed Microsoft to link any word on a web page to another site chosen by the company. Google said none of the companies which received AutoLinks had paid for the service. Some users said AutoLink would only be fair if websites had to sign up to allow the feature to work on their pages or if they received revenue for any \"click through\" to a commercial site. Cory Doctorow, European outreach coordinator for digital civil liberties group Electronic Fronter Foundation, said that Google should not be penalised for its market dominance. \"Of course Google should be allowed to direct people to whatever proxies it chooses. \"But as an end user I would want to know - 'Can I choose to use this service?, 'How much is Google being paid?', 'Can I substitute my own companies for the ones chosen by Google?'.\" Mr Doctorow said the only objection would be if users were forced into using AutoLink or \"tricked into using the service\".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generation :  0\n",
      "\n",
      "\n",
      "New population--\t Fitness Score\n",
      "[14 13  4  0  5  9 20] -> 0.04634348388106095\n",
      "[ 1  2 21 20 10 15  5] -> 0.046933482378574864\n",
      "[16 14  4  3  2  1 12] -> 0.05015334408255304\n",
      "[18  8  5 14 15 17 22] -> 0.048857434543889654\n",
      "[14 11  3  2 13 12  7] -> 0.052660921751948316\n",
      "[ 6 12  7 20  4  1  3] -> 0.03845297945570258\n",
      "[ 1 17 16 15  3 18  8] -> 0.04908149033188957\n",
      "[ 1 17 13 11  4  5 19] -> 0.048377367921437694\n",
      "[ 1 11  6 17  7 14 20] -> 0.041221819970275665\n",
      "[19 17 13 12  9  5  2] -> 0.05118520821763668\n",
      "[ 8 16 18 20 19  0  3] -> 0.04998950937710842\n",
      "[ 3 15 11 17 20  6  1] -> 0.03943678706342026\n",
      "[ 8 18 17  3 16 11 10] -> 0.04524244943132983\n",
      "[12  0  4 20 13 16 22] -> 0.04829013762380586\n",
      "[ 2 20 18 19 12 17  1] -> 0.04432619649666191\n",
      "[ 2  1 17 11  3  8 18] -> 0.043138920172381266\n",
      "[12  2  1  3 13  5  7] -> 0.049657426179271116\n",
      "[13 14 17 19 20 22 16] -> 0.05313213418986158\n",
      "[ 2 15  9 20 10 12  8] -> 0.04897656035273261\n",
      "[ 2  3 14  8 10 11  6] -> 0.05014518023139412\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 5  3 13 10 17 22 18] -> 0.044797715879046594\n",
      "[21 16 18 17  6  1 12] -> 0.04378367461915469\n",
      "\n",
      "\n",
      "Best summary=== ('Google said the feature, available only in the US, \"adds useful links\".', 'The new tool has been compared to the Smart Tags feature from Microsoft by some users.', '\"But as an end user I would want to know - \\'Can I choose to use this service?, \\'How much is Google being paid?', 'Google said none of the companies which received AutoLinks had paid for the service.', '\\', \\'Can I substitute my own companies for the ones chosen by Google?\\'.\"', 'It was widely criticised by net users and later dropped by Microsoft after concerns over trademark use were raised.', 'Mr Doctorow said the only objection would be if users were forced into using AutoLink or \"tricked into using the service\".')\n",
      "\n",
      "\n",
      "Summary Row=== (3, 13, 20, 16, 21, 14, 22)\n",
      "Fitness_value 0.0539425407823162\n",
      "\n",
      "\n",
      "Generation :  1\n",
      "\n",
      "\n",
      "New population--\t Fitness Score\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[13 14 17 19 20 22 16] -> 0.05313213418986158\n",
      "[14 11  3  2 13 12  7] -> 0.052660921751948316\n",
      "[19 17 13 12  9  5  2] -> 0.05118520821763668\n",
      "[16 14  4  3  2  1 12] -> 0.05015334408255304\n",
      "[ 2  3 14  8 10 11  6] -> 0.05014518023139412\n",
      "[ 8 16 18 20 19  0  3] -> 0.04998950937710842\n",
      "[12  2  1  3 13  5  7] -> 0.049657426179271116\n",
      "[ 1 17 16 15  3 18  8] -> 0.04908149033188957\n",
      "[ 2 15  9 20 10 12  8] -> 0.04897656035273261\n",
      "[18  8  5 14 15 17 22] -> 0.048857434543889654\n",
      "[ 3 13 20  8  6 22 16] -> 0.05422097575013925\n",
      "[13 14 17  3  2 12  7] -> 0.05099046265787499\n",
      "[14 11  3 12  9  5  2] -> 0.04670904176212987\n",
      "[19 17 13  3  2  1 12] -> 0.049298246637409705\n",
      "[16 14  4  7 10 11  6] -> 0.04830608146070594\n",
      "[ 2  3 14 21 19  0  4] -> 0.05027363355068983\n",
      "[ 8 16 18  3 13  5  7] -> 0.05730791548743604\n",
      "[12  2  1 14  3 18  8] -> 0.05063020161466385\n",
      "[ 1 17 16 20 10 12  8] -> 0.04610135380437689\n",
      "[ 2 15  9 14  4 17 22] -> 0.04595425008321023\n",
      "[18  8  5 17 21 14 22] -> 0.051264589200856366\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "\n",
      "\n",
      "Best summary=== ('Websites which have paid for advertising on their pages may also be directing people to rival services.', 'Google said none of the companies which received AutoLinks had paid for the service.', 'Cory Doctorow, European outreach coordinator for digital civil liberties group Electronic Fronter Foundation, said that Google should not be penalised for its market dominance.', 'Google said the feature, available only in the US, \"adds useful links\".', 'The new tool has been compared to the Smart Tags feature from Microsoft by some users.', 'AutoLink works by creating a link to a website based on information contained in a webpage - even if there is no link specified and whether or not the publisher of the page has given permission.', 'It could mean online libraries that list ISBN book numbers find they are directing users to Amazon.com whether they like it or not.')\n",
      "\n",
      "\n",
      "Summary Row=== (8, 16, 18, 3, 13, 5, 7)\n",
      "Fitness_value 0.05730791548743604\n",
      "\n",
      "\n",
      "Generation :  2\n",
      "\n",
      "\n",
      "New population--\t Fitness Score\n",
      "[ 8 16 18  3 13  5  7] -> 0.05730791548743604\n",
      "[ 3 13 20  8  6 22 16] -> 0.05422097575013925\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[13 14 17 19 20 22 16] -> 0.05313213418986158\n",
      "[14 11  3  2 13 12  7] -> 0.052660921751948316\n",
      "[18  8  5 17 21 14 22] -> 0.051264589200856366\n",
      "[19 17 13 12  9  5  2] -> 0.05118520821763668\n",
      "[13 14 17  3  2 12  7] -> 0.05099046265787499\n",
      "[12  2  1 14  3 18  8] -> 0.05063020161466385\n",
      "[ 2  3 14 21 19  0  4] -> 0.05027363355068983\n",
      "[ 8 16 18  7  6 22  1] -> 0.047352653888770746\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 3 13 20 19  0 22 16] -> 0.05269579155053893\n",
      "[13 14 17  2  1 12  7] -> 0.049705403091948874\n",
      "[14 11  3 16 21  7 22] -> 0.054515187017565137\n",
      "[18  8  5 11  9  3  2] -> 0.04642683032267834\n",
      "[19 17 13  3  2 12  7] -> 0.052267603319196144\n",
      "[13 14 17 19  3 18  8] -> 0.054060605023761095\n",
      "[12  2  1 21 19  0  4] -> 0.04740364353689665\n",
      "[ 2  3 14  8 13  5  7] -> 0.05762914380826373\n",
      "[ 8 16 18  9  6 22 10] -> 0.04762992164730776\n",
      "\n",
      "\n",
      "Best summary=== (\"It also links to Google's map service, if there is an address, or to car firm Carfax, if there is a licence plate.\", 'Google said the feature, available only in the US, \"adds useful links\".', 'It was widely criticised by net users and later dropped by Microsoft after concerns over trademark use were raised.', 'Websites which have paid for advertising on their pages may also be directing people to rival services.', 'The new tool has been compared to the Smart Tags feature from Microsoft by some users.', 'AutoLink works by creating a link to a website based on information contained in a webpage - even if there is no link specified and whether or not the publisher of the page has given permission.', 'It could mean online libraries that list ISBN book numbers find they are directing users to Amazon.com whether they like it or not.')\n",
      "\n",
      "\n",
      "Summary Row=== (2, 3, 14, 8, 13, 5, 7)\n",
      "Fitness_value 0.05762914380826373\n",
      "\n",
      "\n",
      "Generation :  3\n",
      "\n",
      "\n",
      "New population--\t Fitness Score\n",
      "[ 2  3 14  8 13  5  7] -> 0.05762914380826373\n",
      "[ 8 16 18  3 13  5  7] -> 0.05730791548743604\n",
      "[14 11  3 16 21  7 22] -> 0.054515187017565137\n",
      "[ 3 13 20  8  6 22 16] -> 0.05422097575013925\n",
      "[13 14 17 19  3 18  8] -> 0.054060605023761095\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[13 14 17 19 20 22 16] -> 0.05313213418986158\n",
      "[ 3 13 20 19  0 22 16] -> 0.05269579155053893\n",
      "[ 2  3 14  4 13  5  7] -> 0.052172618543163705\n",
      "[ 8 16 18  5 21  7 22] -> 0.05343859500122546\n",
      "[14 11  3  8  6 22 16] -> 0.05345790664695844\n",
      "[ 3 13 20 19 16 18  8] -> 0.05719187371943724\n",
      "[13 14 17 19 11 22 16] -> 0.05427232797563782\n",
      "[ 3 13 20  5 11 22 16] -> 0.05160446957906112\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 3 13 20 18  3 22 16] -> 0.05270095924508242\n",
      "[13 14 17 18  0 22 16] -> 0.04772293542650027\n",
      "[ 3 13 20  8 10  5  7] -> 0.0536681825726746\n",
      "[ 2  3 14 10 13  5  7] -> 0.05279138749719875\n",
      "\n",
      "\n",
      "Best summary=== (\"It also links to Google's map service, if there is an address, or to car firm Carfax, if there is a licence plate.\", 'Google said the feature, available only in the US, \"adds useful links\".', 'It was widely criticised by net users and later dropped by Microsoft after concerns over trademark use were raised.', 'Websites which have paid for advertising on their pages may also be directing people to rival services.', 'The new tool has been compared to the Smart Tags feature from Microsoft by some users.', 'AutoLink works by creating a link to a website based on information contained in a webpage - even if there is no link specified and whether or not the publisher of the page has given permission.', 'It could mean online libraries that list ISBN book numbers find they are directing users to Amazon.com whether they like it or not.')\n",
      "\n",
      "\n",
      "Summary Row=== (2, 3, 14, 8, 13, 5, 7)\n",
      "Fitness_value 0.05762914380826373\n",
      "\n",
      "\n",
      "Generation :  4\n",
      "\n",
      "\n",
      "New population--\t Fitness Score\n",
      "[ 2  3 14  8 13  5  7] -> 0.05762914380826373\n",
      "[ 8 16 18  3 13  5  7] -> 0.05730791548743604\n",
      "[ 3 13 20 19 16 18  8] -> 0.05719187371943724\n",
      "[14 11  3 16 21  7 22] -> 0.054515187017565137\n",
      "[13 14 17 19 11 22 16] -> 0.05427232797563782\n",
      "[ 3 13 20  8  6 22 16] -> 0.05422097575013925\n",
      "[13 14 17 19  3 18  8] -> 0.054060605023761095\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "[ 3 13 20 19 11 22 16] -> 0.05402018275316173\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 3 13 20 16 21 14 22] -> 0.0539425407823162\n",
      "[ 2  3 14  9 13  5  7] -> 0.05217363983592872\n",
      "[ 8 16 18 19  5 11  6] -> 0.05157943785373083\n",
      "[ 3 13 20 17 21  7 22] -> 0.049169106026606624\n",
      "[14 11  3 19  7 22 16] -> 0.055909887685715774\n",
      "[13 14 17  8  6 22 16] -> 0.052542873045587454\n",
      "[ 3 13 20 19  5 18  8] -> 0.05606073163380234\n",
      "[13 14 17 20 11 22 16] -> 0.04893465380419531\n",
      "[ 3 13 20  0 11 22 16] -> 0.04957636184978816\n",
      "[ 3 13 20 15 21 14 22] -> 0.05262298620338439\n",
      "[ 3 13 20 15 21 14 22] -> 0.05262298620338439\n",
      "[ 3 13 20  9  1  5  7] -> 0.047767507295779214\n",
      "[ 2  3 14  6 13  5  7] -> 0.051943888003389435\n",
      "\n",
      "\n",
      "Best summary=== (\"It also links to Google's map service, if there is an address, or to car firm Carfax, if there is a licence plate.\", 'Google said the feature, available only in the US, \"adds useful links\".', 'It was widely criticised by net users and later dropped by Microsoft after concerns over trademark use were raised.', 'Websites which have paid for advertising on their pages may also be directing people to rival services.', 'The new tool has been compared to the Smart Tags feature from Microsoft by some users.', 'AutoLink works by creating a link to a website based on information contained in a webpage - even if there is no link specified and whether or not the publisher of the page has given permission.', 'It could mean online libraries that list ISBN book numbers find they are directing users to Amazon.com whether they like it or not.')\n",
      "\n",
      "\n",
      "Summary Row=== (2, 3, 14, 8, 13, 5, 7)\n",
      "Fitness_value 0.05762914380826373\n",
      "\n",
      "\n",
      "Overall Best result-----:  (\"It also links to Google's map service, if there is an address, or to car firm Carfax, if there is a licence plate.\", 'Google said the feature, available only in the US, \"adds useful links\".', 'It was widely criticised by net users and later dropped by Microsoft after concerns over trademark use were raised.', 'Websites which have paid for advertising on their pages may also be directing people to rival services.', 'The new tool has been compared to the Smart Tags feature from Microsoft by some users.', 'AutoLink works by creating a link to a website based on information contained in a webpage - even if there is no link specified and whether or not the publisher of the page has given permission.', 'It could mean online libraries that list ISBN book numbers find they are directing users to Amazon.com whether they like it or not.')\n",
      "\n",
      "\n",
      "Best solution :  [[[ 2  3 14  8 13  5  7]]]\n",
      "\n",
      "\n",
      "Best solution fitness :  0.05762914380826373\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy\n",
    "import random\n",
    "from numpy import delete\n",
    "import math\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "def read_article(para):\n",
    "    file = open( r\"C:\\Users\\user\\010.txt\",encoding='utf-8')\n",
    "    filedata = file.read()\n",
    "    print(\"Input file\\n\",filedata)\n",
    "    print(\"\\n\")\n",
    "    sentences= sent_tokenize(filedata)\n",
    "#     print(\"Tokenized Sentences: \",sentences)\n",
    "    total_num_sent=len(sentences)\n",
    "#     print(\"total sentences\",total_num_sent)\n",
    "    sent=word_tokenize(filedata)\n",
    "#     print(sentences)\n",
    "    return sentences\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:]] = freq_table\n",
    "    return frequency_matrix\n",
    "\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "         \n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "            \n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "    sum=0\n",
    "    text=[]\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "        tf_idf_matrix[sent1]= tf_idf_table\n",
    "#         print(tf_idf_matrix[sent1])\n",
    "    return tf_idf_matrix\n",
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    text = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        \n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        text[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "#     print(\"tf_idf score for all the sentences\",text)   \n",
    "    return text\n",
    "\n",
    "def average_value(final_score): \n",
    "    return sum(final_score) / len(final_score)\n",
    "def extract_avg(max_key,new_dict):\n",
    "    max_avg=new_dict.get(max_key)\n",
    "    \n",
    "    return max_avg\n",
    "\n",
    "def max_avg(new_dict):\n",
    "    max_key = max(new_dict, key=new_dict. get)\n",
    "#     print(\"max_avg_summary-------\",max_key)\n",
    "    return max_key\n",
    "def pop_row(pop_number):\n",
    "    max_pop = max(pop_number, key=pop_number. get)\n",
    "#     print(\"Summary Row----\",max_pop)\n",
    "    return max_pop\n",
    "\n",
    "def extract_pop_row(text, pop):\n",
    "    avg=[]\n",
    "    new_dict={}\n",
    "    num=int(len(text)/3)\n",
    "    collection_set=[]\n",
    "    solution_pop=len(text)\n",
    "    set_of=[]\n",
    "    pop_of=[]\n",
    "    avg_dict={}\n",
    "    for i in range(solution_pop):\n",
    "        for j in range(num):\n",
    "#             \n",
    "            \n",
    "            set_of.append(text[pop[i][j]])\n",
    "            pop_of.append(pop[i][j])\n",
    "\n",
    "        freq_matrix = _create_frequency_matrix(set_of)\n",
    "        tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "        count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        total_documents=len(set_of)\n",
    "        idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "        tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "        sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "\n",
    "        average=average_value(sentence_scores.values())\n",
    "\n",
    "        avg_dict[tuple(pop_of)]=average\n",
    "        set_of=[]\n",
    "        pop_of=[]\n",
    "#     print(\"ffffff\",avg_dict)\n",
    "    return avg_dict\n",
    "\n",
    "def fit_substitute(text, pop):\n",
    "    avg=[]\n",
    "    new_dict={}\n",
    "    num=int(len(text)/3)\n",
    "    solution_pop=len(text)\n",
    "    set_of=[]\n",
    "    for i in range(solution_pop):\n",
    "        for j in range(num):\n",
    "           \n",
    "            set_of.append(text[pop[i][j]])\n",
    "        freq_matrix = _create_frequency_matrix(set_of)\n",
    "        tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "        count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        total_documents=len(set_of)\n",
    "        idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "        tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "        sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#         print(\"sent_score ---------\",sentence_scores)\n",
    "        average=average_value(sentence_scores.values())\n",
    "#         print(\"Average values---------\",average)\n",
    "        new_dict[tuple(set_of)]=average\n",
    "        set_of=[]\n",
    "       \n",
    "    #print(\"total dictionary value\",new_dict)\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def cal_pop_fitness(text, pop):\n",
    "   \n",
    "    avg=[]\n",
    "    num=int(len(text)/3)\n",
    "    solution_pop=len(text)\n",
    "    set_of=[]\n",
    "    for i in range(solution_pop):\n",
    "        for j in range(num):\n",
    "            set_of.append(text[pop[i][j]])\n",
    "       \n",
    "        freq_matrix = _create_frequency_matrix(set_of)\n",
    "        tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    \n",
    "        count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        total_documents=len(set_of)\n",
    "        idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "        tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    \n",
    "        sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#         print(\"sent_score ---------\",sentence_scores)\n",
    "        average=average_value(sentence_scores.values())\n",
    "        \n",
    "        set_of=[]\n",
    "        \n",
    "        avg.append(average)\n",
    "    \n",
    "    return avg\n",
    "   \n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = numpy.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "#         print(\"\",max_fitness_idx)\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -99999999999\n",
    "        \n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "#     print(offspring_size[0])\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover,pop_size):\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        random_value = numpy.random.uniform(-1.0, 1.0, 1)\n",
    "#         random_value = numpy.random.randint(low=1, high=20, size=1)\n",
    "#         print(random_value)\n",
    "        ran_size=random_value*pop_size\n",
    "#         print(\"after multiplying\",ran_size)\n",
    "        ran_final=np.round(ran_size)\n",
    "#         print(\"Rounding of\",ran_final)\n",
    "    \n",
    "        offspring_crossover[idx, 3] = offspring_crossover[idx, 3] +random_value\n",
    "#         offspring_crossover[idx,4]= offspring_crossover[idx,4]%pop_size\n",
    "    offspring=np.around(offspring_crossover)\n",
    "    return offspring\n",
    "def recreate_mutation(offspring_crossover,mutation,sol_per_pop):\n",
    "    num=int(sol_per_pop/3)\n",
    "\n",
    "    for i in range(offspring_crossover.shape[0]):\n",
    "        k=1\n",
    "        for j in range(num-1):\n",
    "            k=j+1\n",
    "            if(j!=k):\n",
    "                while k < num:\n",
    "                    if(mutation[i][j]==mutation[i][k]):\n",
    "#                         print(mutation[i][j],mutation[i][k])\n",
    "#                         print(mutation[i])\n",
    "                        b=numpy.random.randint(low=0,high=sol_per_pop-10,size=1)\n",
    "                        if (b not in mutation[i]):\n",
    "                            mutation[i][k]=b\n",
    "#                             print(mutation[i][k])\n",
    "                        else:\n",
    "                            b=numpy.random.randint(low=0,high=sol_per_pop,size=1)\n",
    "                            mutation[i][k]=b\n",
    "#                         print(mutation[i][k])\n",
    "#                         print(\"LLLL\",mutation[i])\n",
    "                    k=k+1\n",
    "            k=1\n",
    "    return mutation\n",
    "def generate_summary(para, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "#     summarize_text = []\n",
    "    b=[]\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(para)\n",
    "    \n",
    "    total_documents = len(sentences)\n",
    "    text=sentences\n",
    "#     print(\"sentence of the documet: \\t\",total_documents)\n",
    "    numbers=[]\n",
    "    for i in range(0, total_documents ):\n",
    "        numbers.append(i)\n",
    "    values_sent=list(numbers)\n",
    "    num_weights=int(len(sentences)/3)\n",
    "    sol_per_pop = len(sentences)\n",
    "#     print(sol_per_pop)\n",
    "    num_parents_mating = int(len(sentences)/2)\n",
    "    pop_size = (sol_per_pop,num_weights) # The population will have sol_per_pop chromosome where each chromosome has num_weights genes.\n",
    "#Creating the initial population.\n",
    "\n",
    "    own_dict={}\n",
    "    for i in range(sol_per_pop):\n",
    "            a=random.sample(values_sent,k=num_weights)\n",
    "            b.append(a)\n",
    "#     print(\"\\n\")\n",
    "           \n",
    "    new_population=numpy.array(b)   \n",
    "#     new_population = numpy.random.uniform(low=0, high=sol_per_pop, size=pop_size)\n",
    "    num_generations = 5\n",
    "    for generation in range(num_generations):\n",
    "        print(\"\\n\")\n",
    "        print(\"Generation : \", generation)\n",
    "        print(\"\\n\")\n",
    "        fitness = cal_pop_fitness(text, new_population)\n",
    "        print(\"New population--\\t Fitness Score\")\n",
    "        for i in range(sol_per_pop):\n",
    "            print(new_population[i],\"->\",fitness[i])\n",
    "#         print(\"Total Fitness scores for this generation ---------\",fitness)\n",
    "        sub=fit_substitute(text,new_population)\n",
    "        print(\"\\n\")\n",
    "        avg_final=max_avg(sub)\n",
    "        print(\"Best summary===\",avg_final)\n",
    "        print(\"\\n\")\n",
    "        pop_number=extract_pop_row(text, new_population)\n",
    "        max_avg_pop=pop_row(pop_number)\n",
    "        print(\"Summary Row===\",max_avg_pop)\n",
    "        average=extract_avg(avg_final,sub)\n",
    "#         print(\"\\n\")\n",
    "        print(\"Fitness_value\",average)\n",
    "        own_dict[avg_final]=average\n",
    "       \n",
    "        # Selecting the best parents in the population for mating.\n",
    "        parents = select_mating_pool(new_population, fitness, num_parents_mating)\n",
    "#         print(parents)\n",
    "        offspring_crossover = crossover(parents,offspring_size=(pop_size[0]-parents.shape[0], num_weights))\n",
    "#         print(\":::\",offspring_crossover)\n",
    "        offspring_mutation = mutation(offspring_crossover,sol_per_pop)\n",
    "#         print(\"offspring_mutation---\\n\", offspring_mutation)\n",
    "        extract1=recreate_mutation(offspring_crossover,offspring_mutation,sol_per_pop)\n",
    "#         print(extract1)\n",
    "        new_population[0:parents.shape[0], :] = parents\n",
    "        new_population[parents.shape[0]:, :] = extract1\n",
    "    max_key = max(own_dict, key=own_dict. get)    \n",
    "    print(\"\\n\")\n",
    "    print(\"Overall Best result-----: \",max_key)\n",
    "    f=open(\"output_file.txt\",'w')\n",
    "    f.write(str(max_key))\n",
    "    f.close()\n",
    "    fitness = cal_pop_fitness(text, new_population)\n",
    "#    Then return the index of that solution corresponding to the best fitness.\n",
    "    best_match_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print (\"Best solution : \", new_population[best_match_idx, :])#values grater than average value\n",
    "    print(\"\\n\")\n",
    "    print(\"Best solution fitness : \",max(fitness))\n",
    "\n",
    "\n",
    "\n",
    "generate_summary( \"msft.txt\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
