{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generation :  0\n",
      "New population-- [[ 7 19 14  3  4 19]\n",
      " [ 3 14  0  2  0  6]\n",
      " [ 1  7  5 10  3 12]\n",
      " [ 9  6 16 10 10  6]\n",
      " [ 4  0 14  4  0 18]\n",
      " [ 6  4  1  7 14 14]\n",
      " [18 17 12  1 10 18]\n",
      " [13  9 15  7  3 19]\n",
      " [ 2 15  6  3  8  4]\n",
      " [ 7 10 18  1 19  4]\n",
      " [ 1 16  0 18 14 15]\n",
      " [14  5  8  5  9 13]\n",
      " [ 8 18 10 14 16 13]\n",
      " [10 16 11  6  7 19]\n",
      " [ 7  7  4  1 14  2]\n",
      " [ 1  2  6 10 15  0]\n",
      " [ 0 10  4 14 19  0]\n",
      " [ 2 18 10  1 13  3]\n",
      " [17  3 19  1  7  9]\n",
      " [16 15 15 11  3 19]]\n",
      "best summary=== ('The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales.', 'TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.', 'It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.', \"Time Warner's fourth quarter profits were slightly better than analysts' expectations.\", 'TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators.')\n",
      "\n",
      "\n",
      "Generation :  1\n",
      "New population-- [[12 16  1 16 17  9]\n",
      " [ 1 17 15  6  2  9]\n",
      " [17  6 14  2  2 17]\n",
      " [ 9  0  8 18  0 19]\n",
      " [ 8  3  8 12  5  9]\n",
      " [15 18  7  5 16  8]\n",
      " [ 3  0 13  7 19  0]\n",
      " [ 9 11  7 17 10  4]\n",
      " [ 2  4  8  4 19 19]\n",
      " [ 8 10 11 18  6  2]\n",
      " [16 19 17 10  1  3]\n",
      " [14 16  6 15  8 14]\n",
      " [19 18 15  7 13  1]\n",
      " [ 4 15 11  4 13  8]\n",
      " [18  1 13  2  3 16]\n",
      " [13  8  4  4  1  2]\n",
      " [ 4  8  5 14  2 13]\n",
      " [ 3 19  3 10  7 17]\n",
      " [16 12  0 13  1 13]\n",
      " [ 6 13  6  5 11 13]]\n",
      "best summary=== ('TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', \"It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband.\", 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.')\n",
      "\n",
      "\n",
      "Generation :  2\n",
      "New population-- [[ 5 11 11 18  5  8]\n",
      " [18  6  8  5  1 19]\n",
      " [17 17  8  3 18 17]\n",
      " [17  4  6  4 19 12]\n",
      " [11  2  9  9 15  3]\n",
      " [11  2 14  5  9 16]\n",
      " [ 8  1  8 18 19  3]\n",
      " [17 12  0 17 12  5]\n",
      " [13 14 11 12 11 15]\n",
      " [14 14 16 13  8  5]\n",
      " [16  3 19  6  7 15]\n",
      " [ 6 16 11 10 16 17]\n",
      " [16  5  6 12  6 19]\n",
      " [19  1  9  0 17 15]\n",
      " [ 0 14  6  5 10 14]\n",
      " [17  2 13  2 18 13]\n",
      " [16  3 15  2  7  5]\n",
      " [ 8 13 19  9  5  2]\n",
      " [ 4 16  9  5  1  0]\n",
      " [10 19 13  1 13  4]]\n",
      "best summary=== ('The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.')\n",
      "\n",
      "\n",
      "Generation :  3\n",
      "New population-- [[19  6  0  9 10  3]\n",
      " [ 1  3  0 14  2 13]\n",
      " [15 17  1 15 10 14]\n",
      " [ 5  3 13  0 11 18]\n",
      " [11 10 19  7 19  8]\n",
      " [ 8 13 10  0 14  6]\n",
      " [14 10 16 14  7 18]\n",
      " [ 7  0  5 10  1 16]\n",
      " [10 15  4  3 12 12]\n",
      " [ 0 12  3 17 12  5]\n",
      " [ 4  6 19 11  3  6]\n",
      " [19  9 14  1 12 10]\n",
      " [ 5  4 18  4  5 14]\n",
      " [10 16  6 10  9 16]\n",
      " [ 4 12  6  5  8  6]\n",
      " [15 19 16  0 15  8]\n",
      " [ 9 13 12  3  8 12]\n",
      " [ 2  0 15  4  5  6]\n",
      " [15  0  4  0 11 11]\n",
      " [ 1 13  6 17 10  0]]\n",
      "best summary=== ('But its own internet business, AOL, had has mixed fortunes.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', \"It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue.\", 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'But its own internet business, AOL, had has mixed fortunes.')\n",
      "\n",
      "\n",
      "Generation :  4\n",
      "New population-- [[14  2 15  7 13 13]\n",
      " [ 9  8  8 18  9 12]\n",
      " [13 11  0  0 12 16]\n",
      " [10 17 11  8 16 14]\n",
      " [ 8  3 18  9 15  8]\n",
      " [14  1 16 14 10  3]\n",
      " [ 5 19  6 17  2 15]\n",
      " [11 13 17 18 17  1]\n",
      " [19  1 18  4 17  3]\n",
      " [16  7  6 15  3 10]\n",
      " [19  2  8 17  7  4]\n",
      " [ 1 11 16  9  7  1]\n",
      " [14 18 11  6 19  7]\n",
      " [12 12 14 16 16  0]\n",
      " [19 18 10  2 13 19]\n",
      " [ 0  6 17  9  4 17]\n",
      " [17  0  8 13 11 18]\n",
      " [15 11  5  6 12  6]\n",
      " [ 0 17 14 14  8  6]\n",
      " [ 5 19 12 16 10  7]]\n",
      "best summary=== ('But its own internet business, AOL, had has mixed fortunes.', 'It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.', 'It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.', 'The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m.', 'TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.')\n",
      "\n",
      "\n",
      "Best result-----:  ('The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.')\n",
      "\n",
      "\n",
      "Best solution :  [[[ 5 19  6  4 16  3]]]\n",
      "\n",
      "\n",
      "Best solution fitness :  0.06721331581844128\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy\n",
    "from numpy import delete\n",
    "import math\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "def read_article(para):\n",
    "    file = open( r\"C:\\Users\\user\\001.txt\",encoding='utf-8')\n",
    "    filedata = file.read()\n",
    "    print(\"Input file\",filedata)\n",
    "    print(\"\\n\\n\")\n",
    "    sentences= sent_tokenize(filedata)\n",
    "#     print(\"Tokenized Sentences: \",sentences)\n",
    "    total_num_sent=len(sentences)\n",
    "#     print(\"total sentences\",total_num_sent)\n",
    "    sent=word_tokenize(filedata)\n",
    "#     print(sentences)\n",
    "    return sentences\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "   \n",
    "    \n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "      \n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            #word = ps.stem(word)\n",
    "            #print(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "         \n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "            \n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "    sum=0\n",
    "    text=[]\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "        tf_idf_matrix[sent1]= tf_idf_table\n",
    "#         print(tf_idf_matrix[sent1])\n",
    "    return tf_idf_matrix\n",
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    text = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        \n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        text[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "#     print(\"tf_idf score for all the sentences\",text)   \n",
    "    return text\n",
    "\n",
    "\n",
    "# def cosine_value(sentences):\n",
    "#     count_vectorizer = CountVectorizer(stop_words='english')\n",
    "#     count_vectorizer = CountVectorizer()\n",
    "#     sparse_matrix = count_vectorizer.fit_transform(sentences)\n",
    "\n",
    "\n",
    "# # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "#     doc_term_matrix = sparse_matrix.todense()\n",
    "#     df = pd.DataFrame(doc_term_matrix, \n",
    "#                   columns=count_vectorizer.get_feature_names(), \n",
    "#                   index=[sentences])\n",
    "#     df\n",
    "#     cosine=cosine_similarity(df, df)\n",
    "# #     print(cosine)\n",
    "#     return cosine\n",
    "\n",
    "def average_value(final_score): \n",
    "    return sum(final_score) / len(final_score)\n",
    "def extract_avg(max_key,new_dict):\n",
    "    max_avg=new_dict.get(max_key)\n",
    "    return max_avg\n",
    "\n",
    "def max_avg(new_dict):\n",
    "    max_key = max(new_dict, key=new_dict. get)\n",
    "#     print(\"max_avg_summary-------\",max_key)\n",
    "    return max_key\n",
    "    \n",
    "\n",
    "def fit_substitute(text, pop):\n",
    "    avg=[]\n",
    "    new_dict={}\n",
    "    num=5\n",
    "    collection_set=[]\n",
    "    solution_pop=18\n",
    "    set_of=[]\n",
    "    for i in range(solution_pop):\n",
    "        for j in range(num):\n",
    "            set_of.append(text[pop[i][j]])\n",
    "        freq_matrix = _create_frequency_matrix(set_of)\n",
    "        tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "        count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        total_documents=len(set_of)\n",
    "        idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "        tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "        sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#         print(\"sent_score ---------\",sentence_scores)\n",
    "        average=average_value(sentence_scores.values())\n",
    "#         print(\"Average values---------\",average)\n",
    "#         print(set_of)\n",
    "#         print(\"\\n\")\n",
    "        new_dict[tuple(set_of)]=average\n",
    "        set_of=[]\n",
    "#     print(\"------dict---------\",new_dict)\n",
    "   \n",
    "    avg_final=max_avg(new_dict)\n",
    "#     print(\"Max of avg-------\",avg_final)\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def cal_pop_fitness(text, pop):\n",
    "   \n",
    "    avg=[]\n",
    "    new_dict={}\n",
    "#     cal=len(sentence_score)/3\n",
    "    num=5\n",
    "    collection_set=[]\n",
    "    solution_pop=18\n",
    "    set_of=[]\n",
    "    for i in range(solution_pop):\n",
    "        for j in range(num):\n",
    "            set_of.append(text[pop[i][j]])\n",
    "            \n",
    "      \n",
    "        freq_matrix = _create_frequency_matrix(set_of)\n",
    "        tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    \n",
    "        count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        total_documents=len(set_of)\n",
    "        idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "        tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    \n",
    "        sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#         print(\"sent_score ---------\",sentence_scores)\n",
    "        average=average_value(sentence_scores.values())\n",
    "        set_of=[]\n",
    "        \n",
    "        avg.append(average)\n",
    "#     print(\"total average ---------\",avg)\n",
    "    return avg\n",
    "   \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = numpy.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -99999999999\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        random_value = numpy.random.uniform(-1.0, 1.0, 1)\n",
    "        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value\n",
    "    return offspring_crossover\n",
    "def generate_summary(para, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "    \n",
    "    \n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(para)\n",
    "    \n",
    "    total_documents = len(sentences)\n",
    "#     print(total_documents)\n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    #print(\"freqency_matrix\",freq_matrix)\n",
    "\n",
    "    \n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    #print(\"tf_matrix:\",tf_matrix)\n",
    "    count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        \n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "    #print(\"idf_matrix\",idf_matrix)\n",
    "\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    #print(\"\\n\\n\")\n",
    "    #print(\"tf-idf: \",tf_idf_matrix)\n",
    "    sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "    \n",
    "    \n",
    "#     print(sentence_scores)\n",
    "#     text= list(sentence_scores.values())\n",
    "#     print(\"Input_values--\",text)\n",
    "    text=list(sentence_scores.keys())\n",
    "#     print(\"sentence of the documet: \\t\",text)\n",
    "    numbers=[]\n",
    "    for i in range(0, total_documents ):\n",
    "        numbers.append(i)\n",
    "    values_sent=list(numbers)\n",
    "#    \n",
    "    num_weights=int(len(sentence_scores)/3)\n",
    "#     print(\"required size--- \",num_weights)\n",
    "    sol_per_pop = len(sentence_scores)\n",
    "#     print(\"Total sent----\",sol_per_pop)\n",
    "    num_parents_mating = 6\n",
    "   \n",
    "    pop_size = (sol_per_pop,num_weights) # The population will have sol_per_pop chromosome where each chromosome has num_weights genes.\n",
    "#Creating the initial population.\n",
    "   \n",
    "    own_dict={}\n",
    "   \n",
    "    num_generations = 5\n",
    "    for generation in range(num_generations):\n",
    "        print(\"Generation : \", generation)\n",
    "        new_population =numpy.random.choice(values_sent,pop_size)\n",
    "        print(\"New population--\",new_population)\n",
    "#         print(\"\\n\")\n",
    "    \n",
    "        fitness = cal_pop_fitness(text, new_population)\n",
    "        sub=fit_substitute(text,new_population)\n",
    "        avg_final=max_avg(sub)\n",
    "        print(\"best summary===\",avg_final)\n",
    "        print(\"\\n\")\n",
    "        average=extract_avg(avg_final,sub)\n",
    "        own_dict[avg_final]=average\n",
    "       \n",
    "        # Selecting the best parents in the population for mating.\n",
    "        parents = select_mating_pool(new_population, fitness, num_parents_mating)\n",
    "        #print(\"parents---\",parents)\n",
    "#         print(\"\\n\")\n",
    "\n",
    "        # Generating next generation using crossover.\n",
    "        offspring_crossover = crossover(parents,\n",
    "                                       offspring_size=(pop_size[0]-parents.shape[0], num_weights))\n",
    "\n",
    "#         print(\"offspring_crossover----\", offspring_crossover)\n",
    "#         print(\"\\n\")\n",
    "   \n",
    "        offspring_mutation = mutation(offspring_crossover)\n",
    "#         print(\"offspring_mutation---\", offspring_mutation)\n",
    "   \n",
    "        new_population[0:parents.shape[0], :] = parents\n",
    "        new_population[parents.shape[0]:, :] = offspring_mutation\n",
    "    max_key = max(own_dict, key=own_dict. get)    \n",
    "  \n",
    "    print(\"Best result-----: \",max_key)\n",
    "    fitness = cal_pop_fitness(text, new_population)\n",
    "#    Then return the index of that solution corresponding to the best fitness.\n",
    "    best_match_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "    print(\"\\n\")\n",
    "    print (\"Best solution : \", new_population[best_match_idx, :])#values grater than average value\n",
    "    print(\"\\n\")\n",
    "    print(\"Best solution fitness : \",max(fitness))\n",
    "\n",
    "\n",
    "\n",
    "generate_summary( \"msft.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thanking you for giving this wounderful oppourtunity for me to talk about my short life span here\n"
     ]
    }
   ],
   "source": [
    "a_dictionary = {\"hai, i am sangeetha and my age is just twenty\": 1, \"After finishing my exams i found that central university is very goog collage\": 2, \"thanking you for giving this wounderful oppourtunity for me to talk about my short life span here\": 3}\n",
    "max_key = max(a_dictionary, key=a_dictionary. get) \n",
    "print(max_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
