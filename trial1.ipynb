{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:    [0.15763237900916954, 0.04979430722411125, 0.05659797923352555, 0.1425404299721975, 0.2314205967018278, 0.035052259304080076, 0.059511971125608035, 0.05981464877322566, 0.054391844343936166, 0.08281348383787532, 0.11280098305869131]\n",
      "New_ population :  [[-0.66416196 -3.07784968  0.25686918  0.32638689  3.92672482  0.08493533]\n",
      " [ 2.6377691   2.53607802 -2.79238227 -0.44395387 -0.14758187 -3.10529043]\n",
      " [ 0.33319919  0.42913654  3.26223143  1.42795998 -2.67091588 -0.91734456]\n",
      " [ 1.48900154 -0.53952774 -1.28894799  2.45921169  3.4548487  -2.21420557]\n",
      " [-1.49382061  0.47065072  2.23832359 -1.15384042 -1.70189868  2.96869912]\n",
      " [-1.15812554  3.41626383  0.53446124  3.932017    0.44171867 -1.1042724 ]\n",
      " [ 1.13085433  3.87023335 -3.24643164 -3.8697287   2.06958766  3.95561069]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.92429299 -2.57894578]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -2.17935002 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.1101013   0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  3.19548914  3.9904294 ]\n",
      " [ 2.08117629 -0.54709395 -0.93067171 -2.51314874  0.18135145  1.56141923]]\n",
      "Generation :  0\n",
      "Fitness Return:  [0.03505226 0.04979431 0.05439184 0.05659798 0.05951197 0.05981465\n",
      " 0.08281348 0.11280098 0.14254043 0.15763238 0.2314206 ]\n",
      "parents:  [[-1.08472356 -1.08958703 -2.57689159  2.65719363  3.19548914  3.9904294 ]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.1101013   0.33114314]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -2.17935002 -0.70539446]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.92429299 -2.57894578]]\n",
      "offspring_crossover:  [[-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.1101013   0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -2.17935002 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.92429299 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.19548914  3.9904294 ]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.1101013   0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -2.17935002 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.92429299 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.19548914  3.9904294 ]]\n",
      "OffSpring mutation:  [[-1.08472356 -1.08958703 -2.57689159 -3.93466437 -2.49976837  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.61238383 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  3.37240095 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.39005926  3.9904294 ]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -2.95616219  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.54240776 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  3.06337667 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  4.08317055  3.9904294 ]]\n",
      "Best result :  0.08281348383787532\n",
      "Generation :  1\n",
      "Fitness Return:  [0.03505226 0.04979431 0.05439184 0.05659798 0.05951197 0.05981465\n",
      " 0.08281348 0.11280098 0.14254043 0.15763238 0.2314206 ]\n",
      "parents:  [[ 0.47300476  1.3821877  -1.38297666  1.46744805  3.06337667 -2.57894578]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.54240776 -0.70539446]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -2.95616219  0.33114314]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.39005926  3.9904294 ]]\n",
      "offspring_crossover:  [[ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.54240776 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -2.95616219  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  3.39005926  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  3.06337667 -2.57894578]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.54240776 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -2.95616219  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  3.39005926  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  3.06337667 -2.57894578]]\n",
      "OffSpring mutation:  [[ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.73366808 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.17182704  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  4.15098261  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.56698814 -2.57894578]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -0.61199926 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.66945908  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  3.42511038  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.63527161 -2.57894578]]\n",
      "Best result :  0.08281348383787532\n",
      "Generation :  2\n",
      "Fitness Return:  [0.03505226 0.04979431 0.05439184 0.05659798 0.05951197 0.05981465\n",
      " 0.08281348 0.11280098 0.14254043 0.15763238 0.2314206 ]\n",
      "parents:  [[-1.08472356 -1.08958703 -2.57689159  2.65719363  3.42511038  3.9904294 ]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.66945908  0.33114314]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -0.61199926 -0.70539446]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.56698814 -2.57894578]]\n",
      "offspring_crossover:  [[-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.66945908  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -0.61199926 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.56698814 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.42511038  3.9904294 ]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.66945908  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -0.61199926 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.56698814 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.42511038  3.9904294 ]]\n",
      "OffSpring mutation:  [[-1.08472356 -1.08958703 -2.57689159 -3.93466437 -4.14613352  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072  0.14488105 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.69225702 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  2.62926372  3.9904294 ]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.25402651  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.32188795 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.70945968 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.10889921  3.9904294 ]]\n",
      "Best result :  0.08281348383787532\n",
      "Generation :  3\n",
      "Fitness Return:  [0.03505226 0.04979431 0.05439184 0.05659798 0.05951197 0.05981465\n",
      " 0.08281348 0.11280098 0.14254043 0.15763238 0.2314206 ]\n",
      "parents:  [[ 0.47300476  1.3821877  -1.38297666  1.46744805  2.70945968 -2.57894578]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.32188795 -0.70539446]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.25402651  0.33114314]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  2.62926372  3.9904294 ]]\n",
      "offspring_crossover:  [[ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.32188795 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.25402651  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  2.62926372  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.70945968 -2.57894578]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.32188795 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -3.25402651  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  2.62926372  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.70945968 -2.57894578]]\n",
      "OffSpring mutation:  [[ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.69692067 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -2.5068724   0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  1.9977047   3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.11421693 -2.57894578]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.45667492 -0.70539446]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -2.82058563  0.33114314]\n",
      " [-1.08472356 -1.08958703 -2.57689159  2.65719363  2.37218595  3.9904294 ]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.25290503 -2.57894578]]\n",
      "Best result :  0.08281348383787532\n",
      "Generation :  4\n",
      "Fitness Return:  [0.03505226 0.04979431 0.05439184 0.05659798 0.05951197 0.05981465\n",
      " 0.08281348 0.11280098 0.14254043 0.15763238 0.2314206 ]\n",
      "parents:  [[-1.08472356 -1.08958703 -2.57689159  2.65719363  2.37218595  3.9904294 ]\n",
      " [-2.40839323 -0.28461336 -3.20604833 -3.93466437 -2.82058563  0.33114314]\n",
      " [ 0.47300476  1.3821877  -1.38297666  2.29942072 -1.45667492 -0.70539446]\n",
      " [-3.97872842 -0.25128419  3.56986155  1.46744805  2.11421693 -2.57894578]]\n",
      "offspring_crossover:  [[-1.08472356 -1.08958703 -2.57689159 -3.93466437 -2.82058563  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.45667492 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.11421693 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  2.37218595  3.9904294 ]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -2.82058563  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.45667492 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.11421693 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  2.37218595  3.9904294 ]]\n",
      "OffSpring mutation:  [[-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.3897793   0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.55482437 -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.80813364 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  1.69503431  3.9904294 ]\n",
      " [-1.08472356 -1.08958703 -2.57689159 -3.93466437 -3.34020129  0.33114314]\n",
      " [-2.40839323 -0.28461336 -3.20604833  2.29942072 -1.400247   -0.70539446]\n",
      " [ 0.47300476  1.3821877  -1.38297666  1.46744805  2.25866487 -2.57894578]\n",
      " [-3.97872842 -0.25128419  3.56986155  2.65719363  3.0096017   3.9904294 ]]\n",
      "Best result :  0.08281348383787532\n",
      "Best solution :  [[[ 0.47300476  1.3821877  -1.38297666  1.46744805  2.25866487\n",
      "   -2.57894578]]]\n",
      "Best solution fitness :  [0.2314206]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy\n",
    "from numpy import delete\n",
    "import math\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "def read_article(para):\n",
    "    file = open( r\"C:\\Users\\user\\vijay.txt\",encoding='utf-8')\n",
    "    filedata = file.read()\n",
    "#     print(filedata)\n",
    "    sentences = sent_tokenize(filedata)\n",
    "    #print(\"Tokenized Sentences: \",sentences)\n",
    "    sent=word_tokenize(filedata)\n",
    "#     print(sentences)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    #ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        #print(words)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            #word = ps.stem(word)\n",
    "            #print(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "         \n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "            \n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "    sum=0\n",
    "    text=[]\n",
    "    \n",
    "\n",
    "    \n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "            \n",
    "        \n",
    "#             print(tf_idf_table[word1])\n",
    "        tf_idf_matrix[sent1]= tf_idf_table\n",
    "#         print(tf_idf_matrix)\n",
    "        \n",
    "    return tf_idf_matrix\n",
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "#     print(sentenceValue[sent])\n",
    "    return sentenceValue\n",
    "\n",
    "def cosine_value(sentences):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(sentences)\n",
    "\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=[sentences])\n",
    "    df\n",
    "    cosine=cosine_similarity(df, df)\n",
    "#     print(cosine)\n",
    "    return cosine\n",
    "def cal_pop_fitness(text, pop):\n",
    "    n=[]\n",
    "    arr=[]\n",
    "    arr1=[]\n",
    "    final=[]\n",
    "    final1=[]\n",
    "    score=[]\n",
    "    k=0\n",
    "    file = open( r\"C:\\Users\\user\\vijay.txt\",encoding='utf-8')\n",
    "    filedata = file.read()\n",
    "    sentences = sent_tokenize(filedata)\n",
    "    cosine=cosine_value(sentences)\n",
    "    x=np.array(cosine)\n",
    "    y=np.argwhere(x>0.8)\n",
    "    for i in range(len(y)): \n",
    "        if(y[i][k] ==y[i][k+1]): \n",
    "            continue\n",
    "\n",
    "        elif(text[y[i][k]]>text[y[i][k+1]]):\n",
    "            n.append(text[y[i][k]])#storing the greater tf_idf score of sentence in array n\n",
    "            arr.append(y[i][k])\n",
    "            arr.append(y[i][k+1])\n",
    "        else:\n",
    "            n.append(text[y[i][k+1]])\n",
    "    arr1=np.unique(arr)\n",
    "#     print(arr1)#returning the comparing sentences\n",
    "    for i in range(len(y)):\n",
    "        if (y[i][k] not in arr1):\n",
    "            final.append(y[i][k])\n",
    "#     print(final)#returning the other sentences\n",
    "    final1=np.unique(final)\n",
    "#     print(final1)\n",
    "    for i in range(len(final1)):\n",
    "        score.append(text[final1[i]])\n",
    "#     print(score)# returning the other sentence score\n",
    "    final_list=[n+score]\n",
    "    final_score=np.unique(final_list)\n",
    "#     print(\"final_score  \",final_score)\n",
    "    return final_score\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = numpy.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -99999999999\n",
    "    return parents\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        random_value = numpy.random.uniform(-1.0, 1.0, 1)\n",
    "        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value\n",
    "    return offspring_crossover\n",
    "def generate_summary(para, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(para)\n",
    "    \n",
    "    total_documents = len(sentences)\n",
    "    \n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    #print(\"freqency_matrix\",freq_matrix)\n",
    "\n",
    "    \n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    #print(\"tf_matrix:\",tf_matrix)\n",
    "    count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "    \n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "    #print(\"idf_matrix\",idf_matrix)\n",
    "\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    #print(\"\\n\\n\")\n",
    "    #print(\"tf-idf: \",tf_idf_matrix)\n",
    "    sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "#     print(sentence_scores)\n",
    "    \n",
    "    \n",
    "#Genetic algorithm part\n",
    "    text=list(sentence_scores.values())\n",
    "    print(\"input:   \",text)\n",
    "    num_weights=6\n",
    "    sol_per_pop = 12\n",
    "    num_parents_mating = 4\n",
    "    # Defining the population size.\n",
    "    pop_size = (sol_per_pop,num_weights) # The population will have sol_per_pop chromosome where each chromosome has num_weights genes.\n",
    "#Creating the initial population.\n",
    "    new_population = numpy.random.uniform(low=-4.0, high=4.0, size=pop_size)\n",
    "    print(\"New_ population : \",new_population)\n",
    "    num_generations = 5\n",
    "    for generation in range(num_generations):\n",
    "        print(\"Generation : \", generation)\n",
    "    # Measing the fitness of each chromosome in the population.\n",
    "        fitness = cal_pop_fitness(text, new_population)\n",
    "        print(\"Fitness Return: \",fitness)\n",
    "        # Selecting the best parents in the population for mating.\n",
    "        parents = select_mating_pool(new_population, fitness, num_parents_mating)\n",
    "        print(\"parents: \",parents)\n",
    "    # Generating next generation using crossover.\n",
    "        offspring_crossover = crossover(parents,\n",
    "                                       offspring_size=(pop_size[0]-parents.shape[0], num_weights))\n",
    "        print(\"offspring_crossover: \",offspring_crossover)\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "        offspring_mutation = mutation(offspring_crossover)\n",
    "        print(\"OffSpring mutation: \", offspring_mutation)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "        new_population[0:parents.shape[0], :] = parents\n",
    "        new_population[parents.shape[0]:, :] = offspring_mutation\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "        print(\"Best result : \",numpy.max(fitness))#numpy.sum(new_population*text, axis=1)))\n",
    "    fitness = cal_pop_fitness(text, new_population)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "    best_match_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "\n",
    "    print(\"Best solution : \", new_population[best_match_idx, :])\n",
    "    print(\"Best solution fitness : \", fitness[best_match_idx])\n",
    "\n",
    "\n",
    "\n",
    "generate_summary( \"msft.txt\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
